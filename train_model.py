import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
import joblib

# 1. CARREGAMENTO DOS DADOS
print("üîÑ Carregando dataset...")
try:
    df = pd.read_csv('smoking_drinking_dataset.csv')
    print(f"‚úÖ Dados carregados! {df.shape[0]} pacientes encontrados.")
except FileNotFoundError:
    print("‚ùå Erro: Arquivo 'smoking_drinking_dataset.csv' n√£o encontrado. Verifique a pasta.")
    exit()

# 2. ENGENHARIA DE DADOS (CRIANDO O "ALVO")
# Aqui definimos a regra m√©dica: Quem √© considerado "Risco" (1) vs "Controle" (0)?
# Regra: Bebe E tem enzimas alteradas OU Fuma E tem press√£o/gordura alterada.

print("‚öôÔ∏è Criando indicadores de risco...")

# Limites de refer√™ncia (simplificados para o modelo)
LIMIT_GTP = 50
LIMIT_ALT = 45
LIMIT_PRESSAO = 140
LIMIT_TRIGLIC = 200 # Triglicer√≠deos alto

def definir_risco(row):
    # Crit√©rio 1: Risco Hep√°tico (Bebe + Enzimas Altas)
    risco_hepatico = (row['DRK_YN'] == 'Y') and (
        row['gamma_GTP'] > LIMIT_GTP or 
        row['SGOT_ALT'] > LIMIT_ALT
    )
    
    # Crit√©rio 2: Risco Cardiovascular (Fuma + Press√£o ou Gordura Alta)
    # SMK_stat_type_cd: 1(Nunca), 2(Ex), 3(Fumante)
    risco_cardio = (row['SMK_stat_type_cd'] == 3) and (
        row['SBP'] > LIMIT_PRESSAO or 
        row['triglyceride'] > LIMIT_TRIGLIC
    )
    
    if risco_hepatico or risco_cardio:
        return 1 # ALERTA VERMELHO
    return 0 # BAIXO RISCO

# Aplica a fun√ß√£o linha a linha
df['Risk_Flag'] = df.apply(definir_risco, axis=1)

print(f"üìä Distribui√ß√£o de Risco:\n{df['Risk_Flag'].value_counts(normalize=True)}")

# 3. PR√â-PROCESSAMENTO
# Transformar texto em n√∫meros para a IA entender

# Mapeamento de Sexo: Male -> 0, Female -> 1
df['sex'] = df['sex'].map({'Male': 0, 'Female': 1})

# Mapeamento de Bebida: N -> 0, Y -> 1
df['DRK_YN'] = df['DRK_YN'].map({'N': 0, 'Y': 1})

# Sele√ß√£o de Features (O que a IA vai olhar para decidir)(CORRIGIDA)
features = [
    'age', 'sex', 'weight', 'waistline', # Perfil
    'SBP', 'DBP', # Press√£o
    'tot_chole', 'LDL_chole', 'triglyceride', # Gorduras (Corrigido aqui: LDL -> LDL_chole)
    'hemoglobin', 'gamma_GTP', 'SGOT_ALT', 'SGOT_AST', # Sangue/F√≠gado
    'SMK_stat_type_cd', 'DRK_YN' # H√°bitos
]

X = df[features] # Dados de entrada
y = df['Risk_Flag'] # O que queremos prever

# Divis√£o Treino (80%) e Teste (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Normaliza√ß√£o (Colocar tudo na mesma escala num√©rica)
# Ex: Idade (50) e GTP (200) ficam em escalas compar√°veis
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. TREINAMENTO DO MODELO
# Usaremos Random Forest: Robusto e explic√°vel
print("\nüß† Treinando a Intelig√™ncia Artificial (Isso pode levar alguns segundos)...")
model = RandomForestClassifier(
    n_estimators=100, # N√∫mero de √°rvores de decis√£o
    max_depth=15,     # Profundidade m√°xima (evita decorar)
    class_weight='balanced', # For√ßa a IA a prestar aten√ß√£o nos casos de Risco (minoria)
    random_state=42,
    n_jobs=-1 # Usa todos os n√∫cleos do processador
)

model.fit(X_train_scaled, y_train)

# 5. AVALIA√á√ÉO
print("\n‚úÖ Treinamento conclu√≠do! Avaliando performance...")
y_pred = model.predict(X_test_scaled)

# Relat√≥rio focado em Recall (Sensibilidade) - Importante para sa√∫de!
print(classification_report(y_test, y_pred))
print("Matriz de Confus√£o:\n", confusion_matrix(y_test, y_pred))

# 6. SALVAMENTO (EXPORTA√á√ÉO)
# Salvamos o Modelo e o Scaler para o App usar depois
print("\nüíæ Salvando o c√©rebro da IA...")
joblib.dump(model, 'modelo_healthguard.pkl')
joblib.dump(scaler, 'scaler.pkl')
print("üéâ Arquivos 'modelo_healthguard.pkl' e 'scaler.pkl' criados com sucesso!")